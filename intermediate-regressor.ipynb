{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba682f49b1aaeb86",
   "metadata": {
    "id": "ba682f49b1aaeb86"
   },
   "source": [
    "# Teacher Student - KD using Intermedia Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740fcaf00eaf41b",
   "metadata": {
    "id": "e740fcaf00eaf41b"
   },
   "source": [
    "##### Teacher Student Network Research\n",
    "Framework adapted from Official Pytorch Knowledge Distillation Tutorial\n",
    "\n",
    "Author:\n",
    "Asad Amiruddin,\n",
    "Harrison Maximillian Rush,\n",
    "Huy N Ho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e4ff9cde85e16",
   "metadata": {
    "id": "a92e4ff9cde85e16"
   },
   "source": [
    "### Import library, datasets, loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00f96571c1c5a3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e00f96571c1c5a3d",
    "outputId": "b7ca4727-c96f-4dd5-8787-8286096fd2f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'captum' already exists and is not an empty directory.\n",
      "/home/hmrush/Masters/CS7643DL/Final Project/Github Repo/teacher-student-network/captum\n",
      "HEAD is now at 4b2eb339 Adding matplotlib to Conda dependencies (#314)\n",
      "Obtaining file:///home/hmrush/Masters/CS7643DL/Final%20Project/Github%20Repo/teacher-student-network/captum\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from captum==0.2.0) (3.8.2)\n",
      "Requirement already satisfied: numpy in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from captum==0.2.0) (1.24.1)\n",
      "Requirement already satisfied: torch>=1.2 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from captum==0.2.0) (2.1.2+cu118)\n",
      "Requirement already satisfied: filelock in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from torch>=1.2->captum==0.2.0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from torch>=1.2->captum==0.2.0) (4.4.0)\n",
      "Requirement already satisfied: sympy in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from torch>=1.2->captum==0.2.0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from torch>=1.2->captum==0.2.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from torch>=1.2->captum==0.2.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from torch>=1.2->captum==0.2.0) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from torch>=1.2->captum==0.2.0) (2.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from matplotlib->captum==0.2.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from matplotlib->captum==0.2.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from matplotlib->captum==0.2.0) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from matplotlib->captum==0.2.0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from matplotlib->captum==0.2.0) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from matplotlib->captum==0.2.0) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from matplotlib->captum==0.2.0) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from matplotlib->captum==0.2.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->captum==0.2.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from jinja2->torch>=1.2->captum==0.2.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/hmrush/miniconda3/envs/mlenv/lib/python3.11/site-packages (from sympy->torch>=1.2->captum==0.2.0) (1.3.0)\n",
      "Installing collected packages: captum\n",
      "  Attempting uninstall: captum\n",
      "    Found existing installation: captum 0.2.0\n",
      "    Uninstalling captum-0.2.0:\n",
      "      Successfully uninstalled captum-0.2.0\n",
      "  Running setup.py develop for captum\n",
      "Successfully installed captum-0.2.0\n",
      "/home/hmrush/Masters/CS7643DL/Final Project/Github Repo/teacher-student-network\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "!git clone https://github.com/pytorch/captum\n",
    "%cd captum\n",
    "!git checkout \"v0.2.0\"\n",
    "!pip3 install -e .\n",
    "import sys\n",
    "sys.path.append('/content/captum')\n",
    "%cd ..\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from time import time\n",
    "from torchvision import models\n",
    "import captum\n",
    "\n",
    "from captum.attr import Saliency, IntegratedGradients, NoiseTunnel, DeepLift, LayerGradCam, LayerAttribution\n",
    "from matplotlib import pyplot as plt\n",
    "from captum.attr import visualization as viz\n",
    "from torchvision import models\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "\n",
    "# Check if GPU is available, and if not, use the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Below we are preprocessing data for CIFAR-10. We use an arbitrary batch size of 128.\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "transform_nonorm = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "# Loading the CIFAR-10 dataset:\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "test_dataset_nonorm = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_nonorm)\n",
    "\n",
    "# Dataloaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "test_loader_nonorm = torch.utils.data.DataLoader(test_dataset_nonorm, batch_size=128, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af03f44164e9de",
   "metadata": {
    "id": "33af03f44164e9de"
   },
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148ed29ebe462888",
   "metadata": {
    "id": "148ed29ebe462888"
   },
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3, min_improv=0.01):\n",
    "        self.patience = patience\n",
    "        self.min_improv = min_improv\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def check_loss(self, validation_loss):\n",
    "      # if validation loss improve by at least min_improv percentage, then\n",
    "      # set min to current loss and reset the counter\n",
    "        if validation_loss <  (self.min_validation_loss * (1 - self.min_improv)):\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "      # else if validation loss exceeds previous loss by the min_improv percentage,\n",
    "      # start counter until hit patience\n",
    "        elif validation_loss > (self.min_validation_loss * (1 + self.min_improv)):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "def train(model, train_loader, epochs, learning_rate, device, early_stop = False):\n",
    "    start = time()\n",
    "    early_stopper = EarlyStopper(patience=3, min_improv=0.1)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # inputs: A collection of batch_size images\n",
    "            # labels: A vector of dimensionality batch_size with integers denoting class of each image\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # outputs: Output of the network for the collection of images. A tensor of dimensionality batch_size x num_classes\n",
    "            # labels: The actual labels of the images. Vector of dimensionality batch_size\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "        if early_stop and early_stopper.check_loss(running_loss):\n",
    "          break\n",
    "    end = time()\n",
    "    runtime = end - start\n",
    "    print(f\"Training Time: {runtime:.3f}\")\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "def train_knowledge_distillation(teacher, student, train_loader, epochs, learning_rate, T, soft_target_loss_weight, device, early_stop = False):\n",
    "    print('Knowledge distillation training')\n",
    "    start = time()\n",
    "    early_stopper = EarlyStopper(patience=3, min_improv=0.1)\n",
    "    ce_loss_weight= 1 - soft_target_loss_weight\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
    "\n",
    "    teacher.eval()  # Teacher set to evaluation mode\n",
    "    student.train() # Student to train mode\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass with the teacher model - do not save gradients here as we do not change the teacher's weights\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "\n",
    "\n",
    "            # Forward pass with the student model\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            #Soften the student logits by applying softmax first and log() second\n",
    "            soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
    "            soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
    "\n",
    "            # Calculate the soft target loss. Scaled by T**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\"\n",
    "            soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (T**2)\n",
    "\n",
    "            # Calculate the true label loss\n",
    "            label_loss = ce_loss(student_logits, labels)\n",
    "\n",
    "            # Weighted sum of the two losses\n",
    "            loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "        if early_stop and early_stopper.check_loss(running_loss):\n",
    "          break\n",
    "    end = time()\n",
    "    runtime = end - start\n",
    "    print(f\"Training Time: {runtime:.3f}\")\n",
    "\n",
    "def show_saliency_map(model, data_loader,title, img_index=3 ):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    input = images[img_index].unsqueeze(0)\n",
    "    original_image = np.transpose((images[img_index].cpu().detach().numpy() / 2) + 0.5, (1, 2, 0))\n",
    "    input.requires_grad = True\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    saliency = Saliency(model)\n",
    "    gradients = saliency.attribute(input, target=labels[img_index].item())\n",
    "    gradients = np.transpose(gradients.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "    classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    img_label = classes[labels[img_index]]\n",
    "    _ = viz.visualize_image_attr(gradients, original_image, method=\"blended_heat_map\", sign=\"absolute_value\",\n",
    "                              show_colorbar=True, title= title + \" - Overlayed Gradient Magnitudes - \" + img_label )\n",
    "    return None\n",
    "\n",
    "def show_integrated_grad(model, data_loader,title , img_index=3 ):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    input = images[img_index].unsqueeze(0)\n",
    "    original_image = np.transpose((images[img_index].cpu().detach().numpy() / 2) + 0.5, (1, 2, 0))\n",
    "    input.requires_grad = True\n",
    "    model.eval()\n",
    "    ig = IntegratedGradients(model)\n",
    "\n",
    "    model.zero_grad()\n",
    "    ig = ig.attribute(input,target=labels[img_index])\n",
    "    ig = np.transpose(ig.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "    classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    img_label = classes[labels[img_index]]\n",
    "    _ = viz.visualize_image_attr(ig, original_image, method=\"blended_heat_map\",sign=\"all\",\n",
    "                              show_colorbar=True, title= title + \" - Overlayed Integrated Gradients - Image #\" + img_label)\n",
    "    return None\n",
    "\n",
    "def layer_gradCAM(model, conv_layer, data_loader,title, img_index=3):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    input = images[img_index].unsqueeze(0)\n",
    "    classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    img_label = classes[labels[img_index]]\n",
    "    original_image = np.transpose((images[img_index].cpu().detach().numpy() / 2) + 0.5, (1, 2, 0))\n",
    "    input.requires_grad = True\n",
    "    model.eval()\n",
    "    layer_gradcam = LayerGradCam(model, conv_layer)\n",
    "    attributions_lgc = layer_gradcam.attribute(input, target=img_index)\n",
    "    upsamp_attr_lgc = LayerAttribution.interpolate(attributions_lgc, input.shape[2:])\n",
    "    _ = viz.visualize_image_attr(upsamp_attr_lgc[0].cpu().permute(1,2,0).detach().numpy(),\n",
    "                             sign=\"all\",\n",
    "                             title=  title + \" Layer GradCAM - Image #\" + img_label)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde8a78adfa4e19",
   "metadata": {
    "id": "bde8a78adfa4e19"
   },
   "source": [
    "### Define deeper neural networks to be used as teachers.\n",
    "Can have multiple teachers for comparison/experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d4aec7840d87",
   "metadata": {
    "id": "fc1d4aec7840d87"
   },
   "source": [
    "### Load resnet50 model with finetuned weight as another teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4780ca82b559df31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4780ca82b559df31",
    "outputId": "c165a9ac-0d04-423d-e239-249573316724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "teacher_resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "teacher_resnet50.fc = nn.Linear(teacher_resnet50.fc.in_features, 10)\n",
    "teacher_resnet50 = teacher_resnet50.to(device)\n",
    "#teacher_resnet50.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/teacher_resnet50.pth\",map_location=device  ))\n",
    "teacher_resnet50.load_state_dict(torch.load(\"./trained_model/teacher_resnet50.pth\",map_location=device))\n",
    "test_accuracy_teacher = test(teacher_resnet50, test_loader, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe046810950e79",
   "metadata": {
    "id": "bffe046810950e79"
   },
   "source": [
    "### Define student network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef6b8911ea191b3",
   "metadata": {
    "id": "cef6b8911ea191b3"
   },
   "outputs": [],
   "source": [
    "# Define the student model\n",
    "# class studentNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(studentNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
    "#         self.fc2 = nn.Linear(512, 10)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(self.relu(self.conv1(x)))\n",
    "#         x = self.pool(self.relu(self.conv2(x)))\n",
    "#         x = self.pool(self.relu(self.conv3(x)))\n",
    "#         x = x.view(-1, 128 * 28 * 28)\n",
    "#         x = self.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# Define another student - this is convNet_Tiny\n",
    "class studentNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(studentNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.conv3(x)  # Direct convolution\n",
    "        x = self.relu(x)   # Activation\n",
    "        x = self.pool2(x)   # Pooling\n",
    "        x = x.view(-1, 128 * 28 * 28)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# Check if GPU is available, and if not, use the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Instantiate the model\n",
    "# studentNN = studentNN().to(device)\n",
    "# test_accuracy_student = test(studentNN, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e65a166b4f447",
   "metadata": {
    "id": "6f9e65a166b4f447"
   },
   "source": [
    "### Instantiate the 2 identical student nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83345791928e709",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c83345791928e709",
    "outputId": "1327bdb8-ecbc-460a-b03f-dcbddc8978c8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the lightweight network:\n",
    "# We instantiate one more lightweight network model to compare their performances.\n",
    "# Back propagation is sensitive to weight initialization,\n",
    "# so we need to make sure these two networks have the exact same initialization.\n",
    "torch.manual_seed(42)\n",
    "learning_student = studentNN().to(device)\n",
    "\n",
    "\n",
    "non_learning_student = studentNN().to(device)\n",
    "\n",
    "# To ensure we have created a copy of the first network, we inspect the norm of its first layer.\n",
    "# If it matches, then we are safe to conclude that the networks are indeed the same.\n",
    "\n",
    "# Print the total number of parameters in each model:\n",
    "total_params_teacher = \"{:,}\".format(sum(p.numel() for p in teacher_resnet50.parameters()))\n",
    "print(f\"DeepNN parameters: {total_params_teacher}\")\n",
    "total_params_non_learning_student = \"{:,}\".format(sum(p.numel() for p in non_learning_student.parameters()))\n",
    "print(f\"non_learning_student parameters: {total_params_non_learning_student}\")\n",
    "total_params_learning_student = \"{:,}\".format(sum(p.numel() for p in learning_student.parameters()))\n",
    "print(f\"learning_student parameters: {total_params_learning_student}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4aa2903489743",
   "metadata": {
    "id": "fdf4aa2903489743"
   },
   "source": [
    "### Train the students and compare to the one without teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7cbc79347a2eed",
   "metadata": {
    "id": "5b7cbc79347a2eed"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "load_non_learning_student_model_from_Gdrive = False   # need to be on Colab\n",
    "load_non_learning_student_model_from_local_hard_drive = False\n",
    "\n",
    "if load_non_learning_student_model_from_Gdrive:\n",
    "    non_learning_student.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/non_learning_student.pth\"  ))\n",
    "elif load_non_learning_student_model_from_local_hard_drive :\n",
    "    non_learning_student.load_state_dict(torch.load(\"./trained_model/non_learning_student.pth\",map_location=device))\n",
    "else:\n",
    "    #train non_learning_student on train dataset\n",
    "    train(non_learning_student, train_loader, epochs=10, learning_rate=0.001, device=device)\n",
    "\n",
    "\n",
    "load_learning_student_model_from_Gdrive = False   # need to be on Colab\n",
    "load_learning_student_model_from_local_hard_drive = False\n",
    "\n",
    "if load_learning_student_model_from_Gdrive:\n",
    "    learning_student.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/learning_student.pth\"  ))\n",
    "elif load_learning_student_model_from_local_hard_drive :\n",
    "    learning_student.load_state_dict(torch.load(\"./trained_model/learning_student.pth\",map_location=device))\n",
    "else:\n",
    "    # Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.\n",
    "    train_knowledge_distillation(teacher=teacher_resnet50, student=learning_student,\n",
    "                                 train_loader=train_loader, epochs=10, learning_rate=0.0005,\n",
    "                                 T=3, soft_target_loss_weight=0.3, device=device)\n",
    "\n",
    "test_accuracy_non_learning = test(non_learning_student, test_loader, device)\n",
    "test_accuracy_learning_student = test(learning_student, test_loader, device)\n",
    "\n",
    "# Compare the student test accuracy with and without the teacher, after distillation\n",
    "# Result shouldn't be stellar because teacher's prediction can't beat ground truth here\n",
    "print(f\"Teacher accuracy: {test_accuracy_teacher:.2f}%\")\n",
    "print(f\"Student accuracy without teacher: {test_accuracy_non_learning:.2f}%\")\n",
    "print(f\"Student accuracy with CE + KD: {test_accuracy_learning_student:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ajbFFvae2x9P",
   "metadata": {
    "id": "ajbFFvae2x9P"
   },
   "source": [
    "###Hyper tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H9_IF4T30UDa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9_IF4T30UDa",
    "outputId": "04e8356a-af69-4785-f1ce-d988cb1c8522"
   },
   "outputs": [],
   "source": [
    "# hyper parameters tuning\n",
    "lr_list = [0.002, 0.001, 0.0005]\n",
    "T_list = [1, 2, 3]\n",
    "soft_target_loss_weight_list = [0.1,  0.25, 0.3]\n",
    "\n",
    "for lr in lr_list:\n",
    "  for T in T_list:\n",
    "    for stl in soft_target_loss_weight_list:\n",
    "      print('Learning Rate - T - Soft Target Loss Weight', lr, T, stl)\n",
    "      train_knowledge_distillation(teacher=teacher_resnet50, student=learning_student,\n",
    "                                 train_loader=train_loader, epochs=10, learning_rate=lr,\n",
    "                                 T=T, soft_target_loss_weight=stl, device=device, early_stop = True)\n",
    "      test_accuracy_learning_student = test(learning_student, test_loader, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20884ad6d26f749",
   "metadata": {
    "id": "20884ad6d26f749"
   },
   "source": [
    "### Save trained models - only run after training on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8d4dff728654d",
   "metadata": {
    "id": "15b8d4dff728654d"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT\n",
    "# change the boolean below to True to save the trained model .pth file into your Google Drive\n",
    "# only work if executing on Google Colab\n",
    "save_model_to_Gdrive = False # need to be on Colab\n",
    "save_model_to_local_drive = True\n",
    "if save_model_to_Gdrive:\n",
    "    torch.save(teacher_resnet50.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/teacher_resnet50.pth\")\n",
    "    torch.save(non_learning_student.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/non_learning_student.pth\") # non-learning student\n",
    "    torch.save(learning_student.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/learning_student.pth\") # student after KD\n",
    "elif save_model_to_local_drive:\n",
    "    torch.save(teacher_resnet50.state_dict(), \"./trained_model/teacher_resnet50.pth\")\n",
    "    torch.save(non_learning_student.state_dict(), \"./trained_model/non_learning_student.pth\") # non-learning student\n",
    "    torch.save(learning_student.state_dict(), \"./trained_model/learning_student.pth\") # student after KD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(non_learning_student.state_dict(), \"./trained_model/non_learning_studen_test.pth\") # non-learning student\n",
    "torch.save(learning_student.state_dict(), \"./trained_model/learning_student_test.pth\") # student after KD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff39812e4a4b02b",
   "metadata": {
    "id": "ff39812e4a4b02b"
   },
   "source": [
    "### Model interpretation    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0737b5920c1a4",
   "metadata": {
    "id": "b6f0737b5920c1a4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a235c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "829a235c",
    "outputId": "ec9b41ea-9264-4ab4-ff68-ca0154bc9ba2"
   },
   "outputs": [],
   "source": [
    "show_saliency_map(model = teacher_resnet50, data_loader = test_loader_nonorm,title = 'Teacher Model', img_index=3)\n",
    "show_saliency_map(model = learning_student, data_loader = test_loader_nonorm,title = 'Student Model', img_index=3)\n",
    "show_integrated_grad(model = teacher_resnet50, data_loader = test_loader_nonorm,title = 'Teacher Model', img_index=3)\n",
    "show_integrated_grad(model = learning_student, data_loader = test_loader_nonorm,title = 'Student Model', img_index=3)\n",
    "\n",
    "model = teacher_resnet50\n",
    "conv_layer = model.layer1[0].conv1\n",
    "layer_gradCAM(model = model, conv_layer = conv_layer, data_loader = test_loader_nonorm, title = 'Teacher Model - Layer 1 Block 0 Conv 1', img_index=3)\n",
    "\n",
    "model = learning_student\n",
    "conv_layer = model.conv3\n",
    "layer_gradCAM(model = model, conv_layer = conv_layer, data_loader = test_loader_nonorm, title = 'Student Model -  Conv 3', img_index=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070fd7ab",
   "metadata": {
    "id": "070fd7ab"
   },
   "source": [
    "# Resnet and Intermediate Feature Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae347b49",
   "metadata": {
    "id": "ae347b49"
   },
   "source": [
    "Found a pretrained resnet32 on Cifar-10. 93% Accuracy reproduceable\n",
    "https://github.com/chenyaofo/pytorch-cifar-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ec37dba",
   "metadata": {
    "id": "0ec37dba"
   },
   "outputs": [],
   "source": [
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c188c6",
   "metadata": {
    "id": "e3c188c6"
   },
   "source": [
    "We set hooks to provide the activation outputs at the specified layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199b754b",
   "metadata": {
    "id": "199b754b"
   },
   "outputs": [],
   "source": [
    "student_learner = studentNN().to(device)\n",
    "student_non_learner = studentNN().to(device)\n",
    "student_first_stage = studentNN().to(device)\n",
    "student_first_stage.load_state_dict(torch.load(\"./trained_model/first_stage_student.pth\"))\n",
    "student_kd_inter_combined = studentNN().to(device)\n",
    "\n",
    "teacher_layer= teacher_resnet50.layer3[0]\n",
    "#teacher_activations = Hook(teacher_layer)\n",
    "\n",
    "student_layer_kd_combine = student_kd_inter_combined.pool2\n",
    "#student_activations = Hook(student_layer_kd_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7941aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e158b59a",
   "metadata": {
    "id": "e158b59a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck(\n",
      "  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "#print(student_activations.output.shape)\n",
    "#print(teacher_activations.output.shape)\n",
    "#print(teacher_resnet50.layer3[0])\n",
    "#print(student_learner.conv3)\n",
    "print(teacher_layer)\n",
    "print(student_layer_kd_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1f3dd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge distillation training\n",
      "Hook Set: Bottleneck(\n",
      "  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Hook Set: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Epoch 1/10, Loss: 3.555685369559871\n",
      "Epoch 2/10, Loss: 2.9911833760683493\n",
      "Epoch 3/10, Loss: 2.7733029800912607\n",
      "Epoch 4/10, Loss: 2.641477893990324\n",
      "Epoch 5/10, Loss: 2.521805175430025\n",
      "Epoch 6/10, Loss: 2.397625275889931\n",
      "Epoch 7/10, Loss: 2.315200444377597\n",
      "Epoch 8/10, Loss: 2.2435612523037456\n",
      "Epoch 9/10, Loss: 2.1762895651180725\n",
      "Epoch 10/10, Loss: 2.1160903065405843\n",
      "Training Time: 625.767\n",
      "Test Accuracy: 10.14%\n"
     ]
    }
   ],
   "source": [
    "student_layer_kd_combine = student_kd_inter_combined.pool2\n",
    "\n",
    "train_kd_intermediate_combined(teacher=teacher_resnet50, \n",
    "                               student=student_kd_inter_combined,\n",
    "                                train_loader=train_loader, \n",
    "                                epochs=10, \n",
    "                                learning_rate=0.0005,\n",
    "                                T=3, \n",
    "                                soft_target_loss_weight=0.3, \n",
    "                                device=device, \n",
    "                                criterion_hint=hint_loss, \n",
    "                                student_layer=student_layer_kd_combine, \n",
    "                                teacher_layer=teacher_layer,\n",
    "                                early_stop=True)\n",
    "\n",
    "kd_combine_results = test(student_learner, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "976b4ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 70.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70.98"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(student_kd_inter_combined, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ac87ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(student_non_learner, train_loader, epochs=10, learning_rate=0.001, device=device)\n",
    "non_learner_results = test(student_non_learner, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4756f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_knowledge_distillation(teacher=teacher_resnet50, student=student_learner,\n",
    "                                 train_loader=train_loader, epochs=10, learning_rate=0.0005,\n",
    "                                 T=3, soft_target_loss_weight=0.3, device=device)\n",
    "learner_results__ = test(student_learner, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d314d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_knowledge_distillation(teacher=teacher_resnet50, student=student_first_stage,\n",
    "                                 train_loader=train_loader, epochs=10, learning_rate=0.0005,\n",
    "                                 T=3, soft_target_loss_weight=0.3, device=device)\n",
    "first_stage_results = test(student_first_stage, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3ce30d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'non_learner_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent accuracy without teacher: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mnon_learner_results\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent accuracy with CE + KD: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearner_results__\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent accuracy with First Stage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_stage_results\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'non_learner_results' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Student accuracy without teacher: {non_learner_results:.2f}%\")\n",
    "print(f\"Student accuracy with CE + KD: {learner_results__:.2f}%\")\n",
    "print(f\"Student accuracy with First Stage: {first_stage_results:.2f}%\")\n",
    "print(f\"Student accuracy with Combined KD: {kd_combine_results:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e74fb7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hook Set: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Hook Set: Bottleneck(\n",
      "  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Test Accuracy: 9.41%\n",
      "9.41\n",
      "Test Accuracy: 95.67%\n",
      "95.67\n",
      "torch.Size([16, 1024, 14, 14])\n",
      "torch.Size([16, 128, 28, 28])\n",
      "torch.Size([16, 128, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "student_test_first_stage = studentNN().to(device)\n",
    "student_layer = student_test_first_stage.pool2\n",
    "test_hook_s = Hook(student_layer)\n",
    "test_hook_t = Hook(teacher_layer)\n",
    "acc = test(student_test_first_stage, test_loader, device)\n",
    "print(acc)\n",
    "acc = test(teacher_resnet50, test_loader, device)\n",
    "print(acc)\n",
    "print(test_hook_t.output.shape)\n",
    "regressor_test = ConvolutionalRegressor2().to(device)\n",
    "x = regressor_test(test_hook_t.output)\n",
    "print(x.shape)\n",
    "print(test_hook_s.output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_test_first_stage = studentNN().to(device)\n",
    "train_first_stage(train_loader, \n",
    "                  student_test_first_stage, \n",
    "                  teacher_resnet50, \n",
    "                  hint_loss, \n",
    "                  10, \n",
    "                  learning_rate=0.001, \n",
    "                  student_layer=student_layer_kd_combine, \n",
    "                  teacher_layer=teacher_layer)\n",
    "test(student_test_first_stage, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f33d1e",
   "metadata": {
    "id": "f3f33d1e"
   },
   "source": [
    "First stage training optimizes up to the hidden layer specified earlier, and uses the loss between teacher and student activations. Afterwards, we continue with the regular training routine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7df784",
   "metadata": {},
   "source": [
    "## RESNET18 Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97394e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390fa3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "batch_size = 128\n",
    "T = 3\n",
    "soft_target_loss_weight = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f75cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = models.resnet18()\n",
    "student.fc = nn.Linear(student.fc.in_features, 10)\n",
    "student = student.to(device)\n",
    "for param in student.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec150573",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = models.resnet50()\n",
    "teacher.fc = nn.Linear(teacher.fc.in_features, 10)\n",
    "teacher.load_state_dict(torch.load('trained_model/teacher_finetuned_cifar10_v2.pth'))\n",
    "teacher = teacher.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea192e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion_kd = nn.KLDivLoss(reduction='batchmean')\n",
    "optimizer = optim.SGD(student.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
