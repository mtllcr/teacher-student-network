{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ba682f49b1aaeb86",
      "metadata": {
        "id": "ba682f49b1aaeb86"
      },
      "source": [
        "# Teacher Student Network Research"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e740fcaf00eaf41b",
      "metadata": {
        "id": "e740fcaf00eaf41b"
      },
      "source": [
        "##### Teacher Student Network Research\n",
        "Framework adapted from Official Pytorch Knowledge Distillation Tutorial\n",
        "\n",
        "Author:\n",
        "Asad Amiruddin,\n",
        "Harrison Maximillian Rush,\n",
        "Huy N Ho"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a92e4ff9cde85e16",
      "metadata": {
        "id": "a92e4ff9cde85e16"
      },
      "source": [
        "### Import library, datasets, loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e00f96571c1c5a3d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T02:47:27.345672Z",
          "start_time": "2024-04-18T02:47:25.628332Z"
        },
        "id": "e00f96571c1c5a3d",
        "outputId": "53f6c4f3-c2fd-4cd7-dc41-1eab81c24595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from time import time\n",
        "from torchvision import models\n",
        "\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "# Check if GPU is available, and if not, use the CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Below we are preprocessing data for CIFAR-10. We use an arbitrary batch size of 128.\n",
        "transform_train = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "# Loading the CIFAR-10 dataset:\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Dataloaders\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33af03f44164e9de",
      "metadata": {
        "id": "33af03f44164e9de"
      },
      "source": [
        "### Define train and test function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "148ed29ebe462888",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T02:47:28.752969Z",
          "start_time": "2024-04-18T02:47:28.733214Z"
        },
        "id": "148ed29ebe462888"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, epochs, learning_rate, device):\n",
        "    start = time()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            # inputs: A collection of batch_size images\n",
        "            # labels: A vector of dimensionality batch_size with integers denoting class of each image\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # outputs: Output of the network for the collection of images. A tensor of dimensionality batch_size x num_classes\n",
        "            # labels: The actual labels of the images. Vector of dimensionality batch_size\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "    end = time()\n",
        "    runtime = end - start\n",
        "    print(f\"Training Time: {runtime:.3f}\")\n",
        "\n",
        "def test(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bde8a78adfa4e19",
      "metadata": {
        "id": "bde8a78adfa4e19"
      },
      "source": [
        "### Define deeper neural networks to be used as teachers.\n",
        "Can have multiple teachers for comparison/experiments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc1d4aec7840d87",
      "metadata": {
        "id": "fc1d4aec7840d87"
      },
      "source": [
        "### Load resnet50 model with finetuned weight as another teacher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4780ca82b559df31",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-04-18T02:47:43.586628Z"
        },
        "jupyter": {
          "is_executing": true
        },
        "id": "4780ca82b559df31"
      },
      "outputs": [],
      "source": [
        "teacher_resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "teacher_resnet50.fc = nn.Linear(teacher_resnet50.fc.in_features, 10)\n",
        "teacher_resnet50 = teacher_resnet50.to(device)\n",
        "teacher_resnet50.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/teacher_resnet50.pth\",map_location=device  ))\n",
        "# teacher_resnet50.load_state_dict(torch.load(\"./trained_model/teacher_resnet50.pth\",map_location=device))\n",
        "test_accuracy_teacher = test(teacher_resnet50, test_loader, device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bffe046810950e79",
      "metadata": {
        "id": "bffe046810950e79"
      },
      "source": [
        "### Define student network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cef6b8911ea191b3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T02:19:28.292260Z",
          "start_time": "2024-04-18T02:19:28.269870Z"
        },
        "id": "cef6b8911ea191b3"
      },
      "outputs": [],
      "source": [
        "# Define the student model\n",
        "class studentNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(studentNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 28 * 28)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Check if GPU is available, and if not, use the CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Instantiate the model\n",
        "# studentNN = studentNN().to(device)\n",
        "\n",
        "# test_accuracy_student = test(studentNN, test_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c77126239715f624",
      "metadata": {
        "id": "c77126239715f624"
      },
      "source": [
        "### Define knowledge distillation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "439176069a736cfa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T02:19:32.186093Z",
          "start_time": "2024-04-18T02:19:32.165506Z"
        },
        "id": "439176069a736cfa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_knowledge_distillation(teacher, student, train_loader, epochs, learning_rate, T, soft_target_loss_weight, ce_loss_weight, device):\n",
        "    print('Knowledge distillation training')\n",
        "    start = time()\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
        "\n",
        "    teacher.eval()  # Teacher set to evaluation mode\n",
        "    student.train() # Student to train mode\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass with the teacher model - do not save gradients here as we do not change the teacher's weights\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher(inputs)\n",
        "\n",
        "            # Forward pass with the student model\n",
        "            student_logits = student(inputs)\n",
        "\n",
        "            #Soften the student logits by applying softmax first and log() second\n",
        "            soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
        "            soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
        "\n",
        "            # Calculate the soft target loss. Scaled by T**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\"\n",
        "            soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (T**2)\n",
        "\n",
        "            # Calculate the true label loss\n",
        "            label_loss = ce_loss(student_logits, labels)\n",
        "\n",
        "            # Weighted sum of the two losses\n",
        "            loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "    end = time()\n",
        "    runtime = end - start\n",
        "    print(f\"Training Time: {runtime:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f9e65a166b4f447",
      "metadata": {
        "id": "6f9e65a166b4f447"
      },
      "source": [
        "### Instantiate the 2 identical student nets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c83345791928e709",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T02:19:59.970038Z",
          "start_time": "2024-04-18T02:19:59.881876Z"
        },
        "id": "c83345791928e709",
        "outputId": "6b9df098-691a-475e-8d6a-d5feffcdcd2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Norm of 1st layer of nn_light: 2.327361822128296\n",
            "Norm of 1st layer of new_nn_light: 2.327361822128296\n",
            "DeepNN parameters: 23,528,522\n",
            "non_learning_student parameters: 267,738\n",
            "learning_student parameters: 267,738\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Instantiate the lightweight network:\n",
        "# We instantiate one more lightweight network model to compare their performances.\n",
        "# Back propagation is sensitive to weight initialization,\n",
        "# so we need to make sure these two networks have the exact same initialization.\n",
        "torch.manual_seed(42)\n",
        "learning_student = studentNN().to(device)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "non_learning_student = studentNN().to(device)\n",
        "\n",
        "# To ensure we have created a copy of the first network, we inspect the norm of its first layer.\n",
        "# If it matches, then we are safe to conclude that the networks are indeed the same.\n",
        "\n",
        "# Print the total number of parameters in each model:\n",
        "total_params_teacher = \"{:,}\".format(sum(p.numel() for p in teacher_resnet50.parameters()))\n",
        "print(f\"DeepNN parameters: {total_params_teacher}\")\n",
        "total_params_non_learning_student = \"{:,}\".format(sum(p.numel() for p in non_learning_student.parameters()))\n",
        "print(f\"non_learning_student parameters: {total_params_non_learning_student}\")\n",
        "total_params_learning_student = \"{:,}\".format(sum(p.numel() for p in learning_student.parameters()))\n",
        "print(f\"learning_student parameters: {total_params_learning_student}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdf4aa2903489743",
      "metadata": {
        "id": "fdf4aa2903489743"
      },
      "source": [
        "### Train the students and compare to the one without teacher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b7cbc79347a2eed",
      "metadata": {
        "id": "5b7cbc79347a2eed"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "load_non_learning_student_model_from_Gdrive = False   # need to be on Colab\n",
        "load_non_learning_student_model_from_local_hard_drive = False\n",
        "\n",
        "if load_non_learning_student_model_from_Gdrive:\n",
        "    non_learning_student.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/non_learning_student.pth\"  ))\n",
        "elif load_non_learning_student_model_from_local_hard_drive :\n",
        "    non_learning_student.load_state_dict(torch.load(\"./trained_model/non_learning_student.pth\",map_location=device))\n",
        "else:\n",
        "    #train non_learning_student on train dataset\n",
        "    train(non_learning_student, train_loader, epochs=10, learning_rate=0.001, device=device)\n",
        "\n",
        "\n",
        "load_learning_student_model_from_Gdrive = False   # need to be on Colab\n",
        "load_learning_student_model_from_local_hard_drive = False\n",
        "\n",
        "if load_learning_student_model_from_Gdrive:\n",
        "    learning_student.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/learning_student.pth\"  ))\n",
        "elif load_learning_student_model_from_local_hard_drive :\n",
        "    learning_student.load_state_dict(torch.load(\"./trained_model/learning_student.pth\",map_location=device))\n",
        "else:\n",
        "    # Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.\n",
        "    train_knowledge_distillation(teacher=teacher_resnet50, student=learning_student,\n",
        "                                 train_loader=train_loader, epochs=10, learning_rate=0.001,\n",
        "                                 T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n",
        "\n",
        "test_accuracy_learning_student = test(learning_student, test_loader, device)\n",
        "test_accuracy_non_learning = test(non_learning_student, test_loader, device)\n",
        "\n",
        "# Compare the student test accuracy with and without the teacher, after distillation\n",
        "# Result shouldn't be stellar because teacher's prediction can't beat ground truth here\n",
        "print(f\"Teacher accuracy: {test_accuracy_teacher:.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_non_learning:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD: {test_accuracy_learning_student:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20884ad6d26f749",
      "metadata": {
        "id": "20884ad6d26f749"
      },
      "source": [
        "### Save trained models - only run after training on Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15b8d4dff728654d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-10T03:31:47.424802Z",
          "start_time": "2024-04-10T03:31:47.395369Z"
        },
        "id": "15b8d4dff728654d"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT\n",
        "# change the boolean below to True to save the trained model .pth file into your Google Drive\n",
        "# only work if executing on Google Colab\n",
        "save_model_to_Gdrive = True # need to be on Colab\n",
        "save_model_to_local_drive = False\n",
        "if save_model_to_Gdrive:\n",
        "    torch.save(teacher_resnet50.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/teacher_resnet50.pth\")\n",
        "    torch.save(non_learning_student.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/non_learning_student.pth\") # non-learning student\n",
        "    torch.save(learning_student.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/learning_student.pth\") # student after KD\n",
        "elif save_model_to_local_drive:\n",
        "    torch.save(teacher_resnet50.state_dict(), \"./trained_model/teacher_resnet50.pth\")\n",
        "    torch.save(non_learning_student.state_dict(), \"./trained_model/non_learning_student.pth\") # non-learning student\n",
        "    torch.save(learning_student.state_dict(), \"./trained_model/learning_student.pth\") # student after KD\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e6bf620d3db47ba",
      "metadata": {
        "id": "6e6bf620d3db47ba"
      },
      "source": [
        "### sandbox section: train the learning student on \"unlabeled\" data/transfer learning/finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3678df67cc433b1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-10T04:26:08.194854Z",
          "start_time": "2024-04-10T04:22:10.064337Z"
        },
        "id": "b3678df67cc433b1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Loading the CIFAR-100 dataset:\n",
        "# train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transforms_cifar)\n",
        "# test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transforms_cifar)\n",
        "#\n",
        "# # Dataloaders\n",
        "#\n",
        "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "#\n",
        "#\n",
        "# # Test accuracy on all 3 models\n",
        "# test_accuracy_teacher = test(teacher, test_loader, device)\n",
        "# test_accuracy_non_learning_student = test(non_learning_student, test_loader, device)\n",
        "# test_accuracy_learning_student = test(learning_student, test_loader, device)\n",
        "# print(f\"Teacher accuracy on CIFAR100 - trained on CIFAR10 only: {test_accuracy_teacher:.2f}%\")\n",
        "# print(f\"non_learning_student accuracy on CIFAR100 test- trained on CIFAR100: {test_accuracy_non_learning_student:.2f}%\")\n",
        "# print(f\"learning_student accuracy on CIFAR100 test - trained on CIFAR10 and teacher's supervision: {test_accuracy_learning_student:.2f}%\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb13bdbf",
      "metadata": {
        "id": "fb13bdbf"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/pytorch/captum\n",
        "\n",
        "%cd captum\n",
        "\n",
        "!git checkout \"v0.2.0\"\n",
        "\n",
        "!pip3 install -e .\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/captum')\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "829a235c",
      "metadata": {
        "id": "829a235c"
      },
      "outputs": [],
      "source": [
        "import captum\n",
        "import captum.attr as captum_attr\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "layer = learning_student.layer4\n",
        "# Create a LayerConductance object\n",
        "lc = captum_attr.LayerConductance(learning_student, layer)\n",
        "\n",
        "# Pass input data through the model\n",
        "attributions = lc.attribute(input_data)\n",
        "\n",
        "# Step 6: Visualize the attribution\n",
        "# Assuming you want to visualize the attributions for a specific image in the batch\n",
        "plt.imshow(attributions[0].cpu().detach().numpy(), cmap='viridis')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "070fd7ab",
      "metadata": {
        "id": "070fd7ab"
      },
      "source": [
        "# Resnet and Intermediate Feature Transfer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae347b49",
      "metadata": {
        "id": "ae347b49"
      },
      "source": [
        "Found a pretrained resnet32 on Cifar-10. 93% Accuracy reproduceable\n",
        "https://github.com/chenyaofo/pytorch-cifar-models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49b0eb4a",
      "metadata": {
        "id": "49b0eb4a"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ec37dba",
      "metadata": {
        "id": "0ec37dba"
      },
      "outputs": [],
      "source": [
        "from helper import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3c188c6",
      "metadata": {
        "id": "e3c188c6"
      },
      "source": [
        "We set hooks to provide the activation outputs at the specified layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "199b754b",
      "metadata": {
        "id": "199b754b"
      },
      "outputs": [],
      "source": [
        "resnet32 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet32\", pretrained=True).to(device)\n",
        "student_inter = studentNN(num_classes=10).to(device)\n",
        "\n",
        "teacher_layer= resnet32.layer2[2]\n",
        "teacher_activations = Hook(teacher_layer)\n",
        "\n",
        "student_layer = student_inter.features[4]\n",
        "student_activations = Hook(student_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60e09a3e",
      "metadata": {
        "id": "60e09a3e",
        "outputId": "f4cb5e7f-7228-4192-f542-0f0e52b3dee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 93.33%\n",
            "Test Accuracy: 9.86%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "9.86"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test(resnet32, test_loader, device)\n",
        "test(student_inter, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e158b59a",
      "metadata": {
        "id": "e158b59a",
        "outputId": "7a2a65ce-16a3-46c2-8580-ab3edade878a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 16, 16, 16])\n",
            "torch.Size([128, 32, 16, 16])\n",
            "Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): BasicBlock(\n",
            "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (3): BasicBlock(\n",
            "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (4): BasicBlock(\n",
            "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "studentNN(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(student_activations.output.shape)\n",
        "print(teacher_activations.output.shape)\n",
        "print(resnet32.layer2)\n",
        "print(student_inter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3f33d1e",
      "metadata": {
        "id": "f3f33d1e"
      },
      "source": [
        "First stage training optimizes up to the hidden layer specified earlier, and uses the loss between teacher and student activations. Afterwards, we continue with the regular training routine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "762d9c773c6e8439",
      "metadata": {
        "id": "762d9c773c6e8439",
        "outputId": "542c6d8e-8b94-4166-92a0-955475a9b6a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 0.05157574638724327\n",
            "Epoch 2/20, Loss: 0.04706999287009239\n",
            "Epoch 3/20, Loss: 0.04581158980727196\n",
            "Epoch 4/20, Loss: 0.04574974253773689\n",
            "Epoch 5/20, Loss: 0.04547273740172386\n",
            "Epoch 6/20, Loss: 0.04224554821848869\n",
            "Epoch 7/20, Loss: 0.04153849184513092\n",
            "Epoch 8/20, Loss: 0.04186097905039787\n",
            "Epoch 9/20, Loss: 0.04079979658126831\n",
            "Epoch 10/20, Loss: 0.04044629633426666\n",
            "Epoch 11/20, Loss: 0.04031776264309883\n",
            "Epoch 12/20, Loss: 0.04033951088786125\n",
            "Epoch 13/20, Loss: 0.04027434065937996\n",
            "Epoch 14/20, Loss: 0.04041905701160431\n",
            "Epoch 15/20, Loss: 0.04043997451663017\n",
            "Epoch 16/20, Loss: 0.040389951318502426\n",
            "Epoch 17/20, Loss: 0.04032289981842041\n",
            "Epoch 18/20, Loss: 0.040344130247831345\n",
            "Epoch 19/20, Loss: 0.040576037019491196\n",
            "Epoch 20/20, Loss: 0.04046780616044998\n",
            "First Stage Training Time: 89.32452321052551\n",
            "Test Accuracy: 10.08%\n",
            "Epoch 1/10, Loss: 1.3600120071864799\n",
            "Epoch 2/10, Loss: 0.828291775320497\n",
            "Epoch 3/10, Loss: 0.6808459966841256\n",
            "Epoch 4/10, Loss: 0.6015299591414459\n",
            "Epoch 5/10, Loss: 0.5538095084907454\n",
            "Epoch 6/10, Loss: 0.5119744504199308\n",
            "Epoch 7/10, Loss: 0.4801327682212186\n",
            "Epoch 8/10, Loss: 0.44693485885629874\n",
            "Epoch 9/10, Loss: 0.41630711781856655\n",
            "Epoch 10/10, Loss: 0.3876985301599478\n",
            "Training Time: 39.363\n",
            "Test Accuracy: 72.02%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "72.02"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "train_first_stage(train_loader, student_inter, resnet32, hint_loss, 10, 0.001)\n",
        "test(student_inter, test_loader, device)\n",
        "train(student_inter, train_loader, epochs=10, learning_rate=0.001, device=device)\n",
        "test(student_inter, test_loader, device)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}